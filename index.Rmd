---
title: "ODEs and Nimble"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, warning = FALSE, dpi = 600)
set.seed(0)
```

## Motivation

I got recently interested in fitting dynamic models specified as a system of ODEs with some observation error on top of it, see e.g. our recent paper [here](https://www.sciencedirect.com/science/article/abs/pii/S2211675320300221) on the colonization of wolf in France (pdf [there](https://oliviergimenez.github.io/pubs/Louvrier2020SpatialStatistics.pdf)).

Also, there has been much activity about dynamic models in relation to the covid-19 pandemic (e.g. [this]( https://statmodeling.stat.columbia.edu/2020/04/02/more-coronavirus-research-using-stan-to-fit-differential-equation-models-in-epidemiology/) or [that](https://www.medrxiv.org/content/10.1101/2020.03.22.20040915v1.article-info)), and I'd like to better understand how these models work, and how parameters are estimated, just out of curiosity.

Now there are several software options to implement these models, such as `OpenBUGS` (see example [here](https://github.com/oliviergimenez/fitODEswithOpenBUGS)), `Jags` pending some tweaks (see [mecastat](https://gitlab.paca.inra.fr/jfrey/jags-module/tree/19b5aefe1ff1b4cf494461650820f802eadc7ff5/mecastat)), `Stan` (see example [here](https://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html)) or other packages like [deBInfer](https://github.com/pboesu/debinfer), [pomp](http://kingaa.github.io/pomp/), [fitR](http://sbfnk.github.io/mfiidd/index.html) or [fitode](https://rdrr.io/github/parksw3/fitode/man/fitode.html) and probably others I do not know of. 

There are also nice introductions to the topic, like [the awesome short course *Model-based Inference in Ecology and Epidemiology* by Aaron King](http://kingaa.github.io/short-course/) and the [book *Epidemics: Models and Data in R* by Ottar N. Bjornstad](https://www.springer.com/gp/book/9783319974866) which comes with [R codes](https://github.com/objornstad/epimdr). 

Here I show how to fit ODE-type models to noisy data using `Nimble`, *a system for building and sharing analysis methods for statistical models, especially for hierarchical models and computationally-intensive methods*, see [here](https://r-nimble.org/) for more details. We begin by writing a `Nimble` function to wrap the `R` ODE solver `deSolve::ode()` that is often used. Thanks Daniel Turek for his help! We first consider a 1D ODE example, then we move to >1D ODE examples for fun. Last, we fit models that are specified with a system of ODEs to noisy data.

Let's load the `Nimble` package:
```{r}
library(nimble)
```

## 1D example

Our first example is a simple logistic growth model $dy/dt= r y (1 - y/K)$. We wrap the `deSolve::ode()` function in a function `R_ode` so that we do not have to parse the name of a function (here `logistic`) as an argument:
```{r}
R_ode <- function(y, times, params) {
    logistic <- function(t, y, parms) return(list(parms[1] * y * (1 - y / parms[2])))
    result <- deSolve::ode(y, times, logistic, params)
    x <- result[,-1]
    return(x)
}
```

Now we write the `Nimble` function with `nimbleRcall`:
```{r}
nimble_ode <- nimbleRcall(
    prototype = function(
        y = double(), # y is a scalar
        times = double(1), # times is a vector
        params = double(1) # params is a vector
    ) {},
    returnType = double(1), # outcome is a vector
    Rfun = 'R_ode'
)
```

Set some values:
```{r}
y <- 0.1 # initial value
times <- seq(from = 0, to = 10, by = 0.01) # time sequence
params <- c(1.5, 10) # r and K
```

Write the `Nimble` code:
```{r}
code <- nimbleCode({
    xOde[1:1001, 1] <- nimble_ode(y, times[1:1001], params[1:2])
})
```

Build and compile le model:
```{r}
constants <- list()
data <- list()
inits <- list(y = y, times = times, params = params)
Rmodel <- nimbleModel(code, constants, data, inits)
Cmodel <- compileNimble(Rmodel)
#Rmodel$calculate()   ## not NA
#Cmodel$calculate()   ## not NA
```

Solve ODE using our brand new `Nimble` function:
```{r}
ode_Nimble <- Rmodel$xOde
head(ode_Nimble)
```

Solve the ODE with native `R` function `deSolve::ode()`:
```{r}
logistic <- function(t, y, parms) return(list(parms[1] * y * (1 - y / parms[2])))
ode_nativeR <- deSolve::ode(y, times, logistic, params)[, -1]
head(ode_nativeR)
```
Compare the two:
```{r}
sum(ode_Nimble - ode_nativeR)
sum(ode_Nimble - ode_nativeR)
```

OK, we're all good. Now let's have a look to a more complex example. 

## 4D example

I use data from a paper by Witkowski and Brais entitled [Bayesian Analysis of Epidemics - Zombies, Influenza, and other Diseases](https://arxiv.org/abs/1311.6376). The authors provide a Python notebook [here](https://gist.github.com/bblais/181abd99f878282666b98a29588dda41). The authors propose the following SEIR epidemic model (more [here](https://github.com/oliviergimenez/SIRcovid19)) to capture the zombie apocalypse:
$$
dS/dt = - \beta S Z \\
dE/dt = \beta S Z - \zeta E \\
dZ/dt = \zeta E - \alpha S Z \\
dR/dt = \alpha S Z
$$
Let us solve this system of ODEs. First, set up some values:
```{r}
y <- c(508.2, 0, 1, 0) # initial values
times <- seq(from = 0, to = 50, by = 1) # time sequence
params <- c(0.2, 6, 0, 508.2) # beta, zeta, alpha, Sinit
```

Write the system of ODEs:
```{r}
shaun <- function(t, y, parms){
  dy1 <- - parms[1] * y[1] * y[3] / parms[4] # S
  dy2 <- parms[1] * y[1] * y[3] / parms[4] - parms[2] * y[2] # E
  dy3 <- parms[2] * y[2] - parms[3] * y[1] * y[3] # Z
  dy4 <- parms[3] * y[1] * y[3] # R
  return(list(c(dy1, dy2, dy3, dy4)))
} 
ode_nativeR <- deSolve::ode(y, times, shaun, params)[, -1]
head(ode_nativeR)
```

Now on to `Nimble`, with the wraper first:
```{r}
R_ode <- function(y, times, params) {
  shaun <- function(t, y, parms){
    dy1 <- - parms[1] * y[1] * y[3] / parms[4] # S
    dy2 <- parms[1] * y[1] * y[3] / parms[4] - parms[2] * y[2] # E
    dy3 <- parms[2] * y[2] - parms[3] * y[1] * y[3] # Z
    dy4 <- parms[3] * y[1] * y[3] # R
    return(list(c(dy1, dy2, dy3, dy4)))
}    
  result <- deSolve::ode(y, times, shaun, params)
  x <- result[,-1]
  return(x)
}
```

Now we write the `Nimble` function with `nimbleRcall`:
```{r}
nimble_ode <- nimbleRcall(
    prototype = function(
        y = double(1), # y is a vector
        times = double(1), # times is a vector
        params = double(1) # params is a vector
    ) {},
    returnType = double(2), # outcome is a matrix
    Rfun = 'R_ode'
)
```

Write the `Nimble` code:
```{r}
code <- nimbleCode({
    xOde[1:51, 1:4] <- nimble_ode(y[1:4], times[1:51], params[1:4])
})
```

Build and compile le model:
```{r}
constants <- list()
data <- list()
inits <- list(y = y, times = times, params = params)
Rmodel <- nimbleModel(code, constants, data, inits)
Cmodel <- compileNimble(Rmodel)
#Rmodel$calculate()   ## not NA
#Cmodel$calculate()   ## not NA
```

Solve ODE using our brand new `Nimble` function:
```{r}
ode_Nimble <- Rmodel$xOde
head(ode_Nimble)
```

Compare with native `R`:
```{r}
sum(ode_Nimble - ode_nativeR)
sum(ode_Nimble - ode_nativeR)
```

It works, awesome ! 

## Add gaussian noise

Now let us have a look to a system with some observation error, which we assume is gaussian. We go on with the zombie example. Briefly speaking, the authors counted the number of living deads in several famous zombie movies. I use the data from [Shaun of the Dead](https://www.imdb.com/title/tt0365748/).

First, we read in the data:
```{r}
tgrid <- c(0.00, 3.00, 5.00, 6.00, 8.00, 10.00, 22.00, 22.20, 22.50, 24.00, 25.50, 
           26.00, 26.50, 27.50, 27.75, 28.50, 29.00, 29.50, 31.50) 
zombies <- c(0, 1, 2, 2, 3, 3, 4, 6, 2, 3, 5, 12, 15, 25, 37, 25, 65, 80, 100)
```

Now the code:
```{r}
code <- nimbleCode({
  
  # system of ODEs
  xOde[1:ngrid, 1:ndim] <- nimble_ode(y[1:ndim], 
                                      times[1:ngrid], 
                                      params[1:ndim])
  # priors on parameters
  params[1] ~ dunif(0, 10) # beta
  params[2] ~ dunif(0, 1) # zeta
  params[3] ~ dunif(0, 0.01) # alpha
  params[4] ~ dunif(300, 600) # Sinit
  
  # observation error
  for (i in 1:ngrid){
    obs_x[i] ~ dnorm(xOde[i, 3], tau.x)
  }
  
  # prior on error sd
  tau.x <- 1 / var.x
  var.x <- 1 / (sd.x * sd.x)
  sd.x ~ dunif(0, 5)
})
```

Specify the constants, data and initial values:
```{r}
# constants
constants <- list(ngrid = 19, 
                  ndim = 4)

# data (pass times and y in constants?)
data <- list(times = tgrid,
             obs_x = zombies,
             y = c(508.2, 0, 1, 0))

# initial values
inits <- list(sdx = 2)
```

Get ready:
```{r}
Rmodel <- nimbleModel(code, constants, data, inits)
# Rmodel$calculate()   ## NA...
conf <- configureMCMC(Rmodel)
conf$printMonitors()
```

```{r}
conf$printSamplers(byType = TRUE)
```

```{r}
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
```

Unleash the beast:
```{r}
samplesList <- runMCMC(Cmcmc, 5000, 
                       nburnin = 1000,
                       nchains = 2,
                       samplesAsCodaMCMC = TRUE)
```

Check out convergence:
```{r}
library(coda)
gelman.diag(samplesList)
```

Visualize traceplots and posterior distributions:
```{r}
library(basicMCMCplots)
chainsPlot(samplesList)
```

Apart from the standard deviation of the observation error, the mixing is poor. This is what I had with `OpenBUGS` too, see [here](https://github.com/oliviergimenez/fitODEswithOpenBUGS/blob/master/README.md). 

Can we do something about that? Hopefully yes, and this is what's great with `Nimble`, you have full control of the underlying MCMC machinery. There are useful advices [here](https://r-nimble.org/better-block-sampling-in-mcmc-with-the-automated-factor-slice-sampler). One reason for poor mixing is correlation in parameters. Let's have a look then. 
```{r}
cor(samplesList$chain1)
cor(samplesList$chain2)
```

Well, we don't have strong correlations, but let's pretend we do for the sake of illustration. Say $\beta$ (params[1]) and $\zeta$ (params[2]) are correlated for example, and let's use block sampling to try and improve mixing. 

First, ask what are the samples used currently: 
```{r}
conf$printSamplers()
```

OK, now remove the default samplers for params[1] and params[3] and use a block random walk instead:
```{r}
conf$removeSamplers(c('params[1]', 'params[2]'))
conf$printSamplers()
conf$addSampler(target = c('params[1]', 'params[2]'),
                type = 'RW_block')
conf$printSamplers()
```

Now rebuild, recompile and rerun:
```{r}
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
samplesList <- runMCMC(Cmcmc, 2500, 
                       nburnin = 1000,
                       nchains = 2,
                       samplesAsCodaMCMC = TRUE)
```

Visualize traceplots and posterior distributions:
```{r}
chainsPlot(samplesList)
```

OK, that's disappointing, again. What if we use another sampler?
```{r}
Rmodel <- nimbleModel(code, constants, data, inits)
conf <- configureMCMC(Rmodel)
conf$printSamplers()
conf <- configureMCMC(Rmodel, onlySlice = TRUE)
conf$printSamplers()
```

Now rebuild, recompile and rerun:
```{r}
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
samplesList <- runMCMC(Cmcmc, 2000, 
                       nburnin = 1000,
                       nchains = 2,
                       samplesAsCodaMCMC = TRUE)
```

Visualize traceplots and posterior distributions:
```{r}
chainsPlot(samplesList)
```

Much slower, and doesn't improve mixing.

Last chance:
```{r}
conf$removeSamplers(c('params[1]', 'params[2]'))
conf$printSamplers()
conf$addSampler(target = c('params[1]', 'params[2]'),
                type = 'AF_slice')
conf$printSamplers()
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
samplesList <- runMCMC(Cmcmc, 2500, 
                       nburnin = 1000,
                       nchains = 2,
                       samplesAsCodaMCMC = TRUE)
chainsPlot(samplesList)
```

## Can we call external code to make the ODE solver faster?

Note that in my attempts above, I call an ODE solver through `R`, which is the slow option. Going full `C/C++` would speed things up. And indeed we can call external code, some `C` code for example, as explained in the help file of function `nimbleExternalCall`. More soon on that.  
```{r eval=FALSE}
?nimbleExternalCall
## Not run: 
sink('add1.h')
cat('
 extern "C" {
 void my_internal_function(double *p, double*ans, int n);
 }
')
sink()
sink('add1.cpp') 
cat('
 #include <cstdio>
 #include "add1.h"
 void my_internal_function(double *p, double *ans, int n) {
   printf("In my_internal_function\\n");
     /* cat reduces the double slash to single slash */ 
   for(int i = 0; i < n; i++) 
     ans[i] = p[i] + 1.0;
 }
')
sink()
system('g++ add1.cpp -c -o add1.o')
Radd1 <- nimbleExternalCall(function(x = double(1), ans = double(1),
n = integer()){}, Cfun =  'my_internal_function',
headerFile = file.path(getwd(), 'add1.h'), returnType = void(),
oFile = file.path(getwd(), 'add1.o'))
## If you need to use a function with non-scalar return object in model code,
## you can wrap it  in another nimbleFunction like this:
model_add1 <- nimbleFunction(
     run = function(x = double(1)) {
         ans <- numeric(length(x))
         Radd1(x, ans, length(x))
         return(ans)
         returnType(double(1))
     })
demoCode <- nimbleCode({
     for(i in 1:4) {x[i] ~ dnorm(0,1)} ## just to get a vector
     y[1:4] <- model_add1(x[1:4])
})
demoModel <- nimbleModel(demoCode, inits = list(x = rnorm(4)),
check = FALSE, calculate = FALSE)
CdemoModel <- compileNimble(demoModel, showCompilerOutput = TRUE)

## End(Not run)
```

## Last one for the road

In a very nice case study, Bob Carpenter shows how to estimate predator-prey population dynamics using Stan, check out [here](https://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html). Let's try and reproduce his results. 

Let's get the data first:
```{r}
library(tidyverse)
dat <- read_csv('https://raw.githubusercontent.com/stan-dev/example-models/master/knitr/lotka-volterra/hudson-bay-lynx-hare.csv', comment = '#')
dat
```

Visualize:
```{r}
dat %>%
  pivot_longer(cols = c('Lynx','Hare'),
               names_to = 'species',
               values_to = 'counts') %>%
ggplot(aes(x = Year, y = counts, color = species)) +
geom_line(size = 0.75) +
geom_point(size = 1.5) +
ylab("Counts (thousands)")
```

Now on to `Nimble`, with the wraper first:
```{r}
# parms = (alpha, beta, gamma, delta)
R_ode <- function(y, times, params) {
  lotka <- function(t, y, parms){
    dy1 <- (parms[1] - parms[2] * y[2]) * y[1] # prey
    dy2 <- (-parms[3] + parms[4] * y[1]) * y[2] # predator
    return(list(c(dy1, dy2)))
}    
  result <- deSolve::ode(y, times, lotka, params, method = "rk4")
  x <- result[,-1]
  return(x)
}
```

Now we write the `Nimble` function with `nimbleRcall`:
```{r}
nimble_ode <- nimbleRcall(
    prototype = function(
        y = double(1), # y is a vector
        times = double(1), # times is a vector
        params = double(1) # params is a vector
    ) {},
    returnType = double(2), # outcome is a matrix
    Rfun = 'R_ode'
)
```

Now the code:
```{r}
code <- nimbleCode({
  
  # system of ODEs
  xOde[1:ngrid, 1:ndim] <- nimble_ode(z_init[1:ndim], 
                                      times[1:ngrid], 
                                      params[1:4])
  # priors on parameters
  params[1] ~ dnorm(1, sd = 0.5) # alpha
  params[2] ~ dnorm(0.05, sd = 0.05) # beta
  params[3] ~ dnorm(1, sd = 0.5) # gamma
  params[4] ~ dnorm(0.05, sd = 0.05) # delta
  
  # observation error
  for (i in 1:ngrid){
    obs_prey[i] ~ dnorm(xOde[i, 1], sd = sdy[1])
    obs_pred[i] ~ dnorm(xOde[i, 2], sd = sdy[2])
  }
  for (k in 1:ndim){
    yinit[k] ~ dnorm(z_init[k], sdy[k])
  }
  # prior on error sd
  for (j in 1:ndim){
    sdy[j] ~ dunif(0,3)
    z_init[j] ~ dnorm(log(10), sd = 1)
  }
})
```

Specify the constants, data and initial values:
```{r}
N <- length(dat$Year) - 1
ts <- 1:N
y_init <- c(dat$Hare[1], dat$Lynx[1])
y <- as.matrix(dat[2:(N + 1), 2:3]) # lynx, hare

# constants
constants <- list(ngrid = N, 
                  ndim = 2)

# data (pass times and y in constants?)
data <- list(times = ts,
             obs_pred = log(y[,1]),
             obs_prey = log(y[,2]),
             yinit = log(y_init))

# initial values
inits <- list(params = c(1, 0.5, 1, 0.5),
              sdy = c(0.2, 0.2),
              z_init = log(c(10, 10)))
```

Get ready:
```{r}
Rmodel <- nimbleModel(code, constants, data, inits)
Rmodel$calculate() # -905...
conf <- configureMCMC(Rmodel)
conf$printMonitors()
```

```{r}
conf$printSamplers(byType = TRUE)
```

```{r}
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
```

Unleash the beast:
```{r}
samplesList <- runMCMC(Cmcmc, 10000, 
                       nburnin = 5000,
                       nchains = 2,
                       samplesAsCodaMCMC = TRUE)
```

Check out convergence:
```{r}
library(coda)
gelman.diag(samplesList)
```

Visualize traceplots and posterior distributions:
```{r}
library(basicMCMCplots)
chainsPlot(samplesList)
```

Summary estimates:
```{r}
summary(samplesList)
```

The estimates we get are not exactly the same as Stan's estimates. Not sure why. 

## R version used

```{r}
sessionInfo()
```

